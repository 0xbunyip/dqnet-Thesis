\chapter{Kiến thức nền tảng}
\begin{quote}
\textit{Trong chương này sẽ trình bày những kiến thức nền tảng của học tăng cường. Trong phần đầu tiên chúng em sẽ trình bày định nghĩa của các thành phần cơ bản trong học tăng cường. Tiếp đó sẽ đề cập đến mô hình Markov Decision Processes được áp dụng trong việc đánh giá lý thuyết một số thành phần của bài toán học tăng cường. Cùng với đó sẽ trình bày qui trình tổng quát để đánh giá và cải thiện chính sách trong bài toán. Cuối cùng chúng em sẽ trình bày một số phương pháp phổ biến thường được áp dụng để đánh giá cũng như cải thiện giúp hệ thông có cách giải tốt hơn cho bài toán trên.}
\end{quote}

\section{Các thành phần cơ bản của học tăng cường}

\section{Mô hình Markov Decision Processes (MDP)}
	\begin{itemize}
			\item Các thành phần MDP
			\item Ví dụ cho mô hình MDP
			\item Phương trình Bellman
			\item Qui trình đánh giá chính sách: Kỹ thuật qui hoạch động
			\item Qui trình cải thiện chính động: Kỹ thuật qui hoạch động
	\end{itemize}

\section{Những phương pháp đánh giá và cải thiện chính sách}
	\begin{itemize}
		\item Dẫn nhập: Trên thực tế ta không có thông tin về môi trường
		\item Qui trình đánh giá chính sách
			\begin{itemize}
				\item[+] Dựa trên hàm giá trị trạng thái: Monte-Carlo, TD(0), n-step TD, TD($\lambda$)
				\item[+] Dựa trên hàm giá trị hành động: Monte-Carlo, Sarsa(0), n-step Sarsa, Sarsa($\lambda$)
			\end{itemize}
		\item Qui trình cải thiện chính sách: Phương pháp greedy
	\end{itemize}
	
